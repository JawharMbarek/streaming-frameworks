\chapter{Einführung}

\begin{quote}
Social media streams, such as Twitter, have shown themselves to be useful sources of real-time information about what is happening in the world. Automatic detection and tracking of events identified in these streams have a variety of real-world applications, e.g. identifying and automatically reporting road accidents for emergency services.
\citelit{mccreadie2013scalable}
\end{quote}

Im Internet steigt das Angebot zu unterschiedlichen Informationen rapide an. Gerade in Deutschland wächst das Datenaufkommen, wie die Studie der IDC \citelit[S. 2-3]{res:idcDuGer} das zeigt, exponentiell. Dabei nimmt ebenfalls das Interesse an wiederkehrenden Aussagen über die Anzahl bestimmter Produkte, die Beziehungen zu Personen und die persönlichen Stimmungen zueinander zu. So wird in \citeint{twt:interactive} eine interaktive Grafik zum Zeitpunkt der Ansprache zur Lage der Union des Präsidenten der USA angezeigt. Je Zeitpunkt und Themenschwerpunkt wird in der Ansprache zeitgleich die Metrik Engagement zu den einzelnen Bundesstaaten aus den verteilten Twitternachrichten berechnet ausgegeben.
%
% Permission requested [http://twtrland.com/] 11.05.2014 to reference streaming frameworks founders on twitter
% Permission allowed

In der Infografik \citeint{res:DataNeverSleeps20} von Josh James, Firma Domo wird ein Datenwachstum von 2011 bis 2013 um 14,3\% veranschaulicht. Es werden unterschiedliche Webseiten vorgestellt. Dabei werden unterschiedlichen Arten von Daten, die pro Minute im Internet erzeugt werden gezeigt. 
In der ersten Fassung \citeint{res:DataNeverSleeps10} waren es noch 2 Millionen Suchabfragen auf der Google-Suchseite \citeint{GoogleDe:search}. Die zweite Fassung gibt über 4 Millionen Suchanfragen pro Minute an. In Facebook \citeint{facebook} konnten in der Fassung mehr als 680 Tausend Inhalte getauscht werden. In der zweiten Fassung werden mehr als 2,4 Millionen Inhalte pro Minute getauscht. 

Um die Sicherheit bei Verlust einer Kreditkarte zu erhöhen und gleichzeitig die höchste Flexibilität zu erhalten, gibt es im Falle eines Schadens bei der von unterschiedlichen Orten gleichzeitig eine unerwünschte Banküberweisung stattfindet, für die Bank die Möglichkeit, die Transaktion aufgrund der Positionserkennung zurückzuführen \citelit[S. 3, K. Integrate Stored and Streaming Data]{res:stonebraker20058}.

Mit steigenden Anforderungen, wie in der Umfrage \citelit[S. 8]{res:kpmgGbtd} durch schnellere Analyse, Erkennung möglicher Fehler und Kostenersparnis dargestellt, und damit einem massiven Datenaufkommen ausgesetzt, kann die herkömmliche Datenverarbeitung \citelit[S. 2, K. Architecure and End-to-End Process]{datawarehouse:Chaudhuri:1997:ODW:248603.248616} durch das Zwischenlagern der Daten in einem Datenzentrum keine komplexen und stetigen Anfragen zeitnah beantworten \citelit[S. 2 K. Related Work: Big Data and Distributed Stream Processing]{mccreadie2013scalable}. Damit müssen Nachrichten, sobald ein Nachrichteneingang besteht, sofort verarbeitet werden können. Allen Goldberg stellt in \citelit[S. 1, K. Stream Processing Example]{esp:Goldberg:1984:SP:800055.802021} anhand eines einfachen Beispiels Stream processing, zu deutsch Verarbeitung eines Nachrichtenstroms ausgehend von loop fusion \citelit[S. 7, K. History]{esp:Goldberg:1984:SP:800055.802021} vor. Da Allen Goldbergs Beschreibung, zu Stream processing, in die Ursprünge geht, soll ein einfaches Modell eines Stream processing Systems für die weitere Betrachtung als Grundlage dienen.

So wird in \citelit[S. 2, K. 2.1: Architecture]{abadi2005design} die distributed stream processing engine Borealis vorgestellt und als große verteilte Warteschlangenverarbeitung beschrieben. Die Abbildung \citelit[S. 3, A. 1: Borealis Architecture]{abadi2005design} zeigt eine Borealis-Node mit Query processor in der Abfragen verarbeitet werden. Eine Borealis-Node entspricht einem Operator, in dem laufend Datentupel sequentiell verarbeitet werden. Mehrere Nodes sind in einem Netzwerk verbunden und lösen dadurch komplexe Abfragen. Damit die Komplexität, die Lastverteilung und somit die Steigerung der Kapazität für die Entwicklung von neuen Anwendungen vereinfacht werden, wurden Streaming frameworks entwickelt. Streaming frameworks stellen auf einer höheren Abstraktion Methoden zur Datenverarbeitung bereit. 

Bisher werden einzelne Streaming frameworks separat in Büchern oder im Internet im Dokumentationsbereich der Produktwebseiten vorgestellt. Dabei werden vorwiegend Methoden des einzelnen Streaming frameworks erläutert und auf weiterführenden Seiten vertieft. Als Software Entwickler wird der Nutzen für die Streaming frameworks nicht sofort klar. Zum Teil sind die Dokumentationen veraltet, in einem Überführungsprozess einer neuen Version oder es fehlt ein schneller Einstieg mit einer kleinen Beispielanwendung.

In dieser Arbeit wird eine Übersicht mit Einordnung und Spezifikation über die einzelnen Streaming frameworks Apache Storm \citeint{storm:home}, Apache Kafka \citeint{kafka:home}, Apache Flume \citeint{flume:home} und Apache S4 \citeint{s4:home} geben. Dabei werden außerdem die Streaming frameworks diskutiert und verglichen. 

%Eventuell eine kurze Passage zur Formatierung von Quelltext und Fremdworten%

Die vorliegende Arbeit ist in Drei Teile aufgebaut. Im ersten Teil erfolgt eine theoretische Einführung in die Grundlagen und einer Analyse mit einem Referenzmodell. Im zweiten Teil werden die Streaming frameworks und ein praxisnaher Anwendungsfall vorgestellt, sowie Messungen durchgeführt. 
Auf der Basis der Erkenntnisse, die in den ersten beiden Teilen gewonnen wurden, werden im dritten Teil die Kernaussagen zusammengefasst sowie ein Ausblick gegeben.

Das erste Kapitel führt mit praktischen Beispielen in das Thema ein. Im zweiten Kapitel werden Grundlagen geschaffen und verwendete Fachbegriffe erläutert. Zudem wird die eingesetzte Technologie vorgestellt, eingeordnet und zusammengefasst. 
Im dritten Kapitel findet eine Analyse eines Referenzmodells statt. Dabei werden unter den gewonnen Grundlagen weitere Fachbegriffe eingeführt und Kriterien für eine Bewertung vorgestellt. Für die weitere Betrachtung der Streaming frameworks, wird abschließend das Referenzmodell bewertet.
Kapitel Vier stellt die einzelnen Streaming frameworks vor. Im Anhang wird jeweils eine Installationsanleitung und ein kurzes Startprogramm als Quelltext abgelegt.
In Kapitel Fünf wird ein Anwendungsfall vorgestellt und die Streaming framewoks werden einem Belastungstest unterzogen.
Das sechste Kapitel stellt das Bewertungsschema vor und stellt die Ergebnisse aus Kapitel Vier und Fünf in einer Übersicht dar. Anschließend werden die Streaming frameworks verglichen und Erkenntnisse werden gezogen.
Das letzte Kapitel greift die Erkenntnisse aus Kapitel Sechs auf und führt in die Schlussbetrachtung ein. Abschließend wird zusammengefasst und ein Ausblick gegeben.
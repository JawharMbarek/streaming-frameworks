\chapter{Einführung}

\begin{quote}
Social media streams, such as Twitter, have shown themselves to be useful sources of real-time information about what is happening in the world. Automatic detection and tracking of events identified in these streams have a variety of real-world applications, e.g. identifying and automatically reporting road accidents for emergency services.
\citelit{mccreadie2013scalable}
\end{quote}

Im Marktplatz Internet steigt das Angebot zu unterschiedlichen Informationen rapide an. Gerade in Deutschland wächst das Datenaufkommen anhand einer Studie der IDC \citelit[S. 2-3]{res:idcDuGer} exponentiell. Dabei nimmt ebenfalls das Interesse an wiederkehrenden Aussagen über die Anzahl bestimmter Produkte, die Beziehungen zu Personen und die persönlichen Stimmungen zueinander zu. Die Infografik \citeint{res:DataNeverSleeps20} von Josh James, Firma Domo zeigt wieviel und welche Art von Daten in einer Minute an unterschiedlichen Stellen im Internet erzeugt werden. 

Um die Sicherheit bei Verlust einer Kreditkarte zu erhöhen und gleichzeitig die höchste Flexibilität zu erhalten, gibt es im Falle eines Schadens bei der von unterschiedlichen Orten gleichzeitig eine unerwünschte Banküberweisung stattfindet, für die Bank die Möglichkeit die Transaktion aufgrund der Positionserkennung zurückzuführen \citelit[S. 3, K. Integrate Stored and Streaming Data]{res:stonebraker20058}.

Durch die steigenden Anforderungen wie zum Beispiel schnellere Analyse, Erkennung möglicher Fehler, Kostenersparnis in der Umfrage \citelit[S. 8]{res:kpmgGbtd} dargestellt, und damit dem massiven Datenaufkommen kann die herkömmliche Datenverarbeitung \citelit[S. 2, K. Architecure and End-to-End Process]{datawarehouse:Chaudhuri:1997:ODW:248603.248616} durch das Zwischenlagern der Daten in einem Datenzentrum keine komplexen und stetigen Anfragen zeitnah beantworten \citelit[S. 2 K. Related Work: Big Data and Distributed Stream Processing]{mccreadie2013scalable}. Im Stream processing werden Nachrichtenströme verarbeitet. Allen Goldberg stellt in \citelit[S. 1, K. Stream Processing Example]{esp:Goldberg:1984:SP:800055.802021} anhand eines einfachen Beispiels Stream processing ausgehend von loop fusion \citelit[S. 7, K. History]{esp:Goldberg:1984:SP:800055.802021} vor. Da Allen Goldbergs Beschreibung zu Stream processing in die Ursprünge geht, soll an dieser Stelle die Erkenntnis über ein einfaches Modell eines Stream processing Servers ähnlich wie in der Abbildung \citelit[S. 3, A. 1: Borealis Architecture]{abadi2005design} als Einstieg dienen. 

In der komplexen Nachrichtenverarbeitung ist die zentrale Stelle in der die Nachrichtenströme verarbeitet werden einem Engpass ausgesetzt. Damit die Komplexität, die Lastverteilung und somit die Steigerung der Kapazität für die Entwicklung vereinfacht werden, wurden Streaming frameworks entwickelt. Streaming frameworks stellen auf einer höheren Abstraktion Methoden zur Datenverarbeitung bereit. Da es unterschiedliche Implementierungen der Streaming frameworks gibt, sollen in dieser Arbeit die Streaming frameworks Apache Storm \citeint{storm:github:wiki:home}, Apache Kafka \citeint{apache:kafka:home}, Apache Flume \citeint{apache:flume:home} und Apache S4 \citeint{apache:s4:home:incubator} diskutiert und verglichen werden. 